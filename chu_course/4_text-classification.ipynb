{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlgxDK2PCnuW"
   },
   "source": [
    "# 第四课 情感分析\n",
    "\n",
    "褚则伟 zeweichu@gmail.com\n",
    "\n",
    "学习目标\n",
    "- 学习和训练文本分类模型\n",
    "- 学习torchtext的基本使用方法\n",
    "    - BucketIterator\n",
    "- 学习torch.nn的一些基本模型\n",
    "    - Conv2d\n",
    "\n",
    "本notebook参考了https://github.com/bentrevett/pytorch-sentiment-analysis\n",
    "\n",
    "在这份notebook中，我们会用PyTorch模型和TorchText再来做情感分析(检测一段文字的情感是正面的还是负面的)。我们会使用[IMDb 数据集](http://ai.stanford.edu/~amaas/data/sentiment/)，即电影评论。\n",
    "\n",
    "模型从简单到复杂，我们会依次构建：\n",
    "- Word Averaging模型\n",
    "- RNN/LSTM模型\n",
    "- CNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAiegk1vCnuX"
   },
   "source": [
    "## 准备数据\n",
    "\n",
    "- TorchText中的一个重要概念是`Field`。`Field`决定了你的数据会被怎样处理。在我们的情感分类任务中，我们所需要接触到的数据有文本字符串和两种情感，\"pos\"或者\"neg\"。\n",
    "- `Field`的参数制定了数据会被怎样处理。\n",
    "- 我们使用`TEXT` field来定义如何处理电影评论，使用`LABEL` field来处理两个情感类别。\n",
    "- 我们的`TEXT` field带有`tokenize='spacy'`，这表示我们会用[spaCy](https://spacy.io) tokenizer来tokenize英文句子。如果我们不特别声明`tokenize`这个参数，那么默认的分词方法是使用空格。\n",
    "- 安装spaCy\n",
    "```\n",
    "pip install -U spacy\n",
    "python -m spacy download en\n",
    "```\n",
    "- `LABEL`由`LabelField`定义。这是一种特别的用来处理label的`Field`。我们后面会解释dtype。\n",
    "- 更多关于`Fields`，参见https://github.com/pytorch/text/blob/master/torchtext/data/field.py\n",
    "- 和之前一样，我们会设定random seeds使实验可以复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5884,
     "status": "ok",
     "timestamp": 1582439797849,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "KTjejir6wulO",
    "outputId": "b5a95157-f965-4721-ec32-5e0b6b3dc645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WxPWgjWCnuZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsPyEOwACnud"
   },
   "source": [
    "- TorchText支持很多常见的自然语言处理数据集。\n",
    "- 下面的代码会自动下载IMDb数据集，然后分成train/test两个`torchtext.datasets`类别。数据被前面的`Fields`处理。IMDb数据集一共有50000电影评论，每个评论都被标注为正面的或负面的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117619,
     "status": "ok",
     "timestamp": 1582441213601,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "b-IBXAlcCnue",
    "outputId": "29c8ca85-100a-40fc-cbeb-702a4a2f6758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.48MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68k4UQkSCnui"
   },
   "source": [
    "查看每个数据split有多少条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1582441237061,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "oUezFGxiCnuk",
    "outputId": "4cbc95ca-b13f-4da6-b40a-04382df8b69b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF9O3v0MCnup"
   },
   "source": [
    "查看一个example。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1710,
     "status": "ok",
     "timestamp": 1582441244174,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "F2TCbBmpCnur",
    "outputId": "45cd7209-2a2b-43d5-fa0e-e2d811266b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['I', 'enjoyed', 'this', 'movie', 'so', 'much', 'that', 'I', 'watched', 'it', 'twice', 'and', 'that', 'is', 'something', 'to', 'say', 'about', 'a', 'documentary', '.', 'The', 'musical', 'score', ',', 'cinematography', 'and', 'sound', 'are', 'absolutely', 'stunning', 'as', 'you', 'might', 'expect', 'from', 'an', 'Imax', 'production', '.', 'Even', 'though', 'it', 'is', 'shot', 'for', 'those', 'huge', 'Imax', 'theaters', ',', 'it', 'looks', 'and', 'sounds', 'wonderful', 'on', 'my', 'home', 'system', '.', 'In', 'fact', 'this', 'would', 'make', 'a', 'perfect', 'DVD', 'to', 'demo', 'your', 'system.<br', '/><br', '/>The', 'subject', 'is', 'also', 'so', 'fascinating', '.', 'It', 'is', 'about', 'Mario', 'Andretti', 'and', 'his', 'son', 'Michael', '.', 'I', 'was', 'already', 'a', 'fan', 'of', 'Mario', 'because', 'he', 'is', 'the', 'best', 'racecar', 'drive', 'in', 'history', 'since', 'he', 'is', 'the', 'only', 'person', 'to', 'win', 'the', 'CART', 'Championship', ',', 'F1', 'Championship', ',', 'The', 'Daytona', '500', 'and', 'the', 'Indianapolis', '500', '.', 'The', 'script', 'follows', 'the', 'path', 'of', 'two', 'cars', 'very', 'important', 'to', 'the', 'father', 'and', 'son', '.', 'The', 'first', 'car', 'is', 'found', 'in', 'a', 'chicken', 'coop', 'and', 'turns', 'out', 'to', 'be', 'the', 'first', 'roadster', 'that', 'Mario', 'ever', 'drove', 'and', 'we', 'follow', 'restoration', 'to', 'gleaming', 'perfection', '.', 'The', 'other', 'car', 'is', 'Michael', \"'s\", 'new', 'racecar', 'and', 'we', 'follow', 'it', 'from', 'cutting', 'the', 'mold', 'through', 'the', 'race', 'season', '.', 'Imax', 'lends', 'just', 'the', 'right', 'magic', 'to', 'make', 'car', 'construction', 'entertaining', 'and', 'fascinating.<br', '/><br', '/>Paul', 'Newman', ',', 'who', 'was', 'Michael', 'Amoretti', \"'s\", 'team', 'owner', 'at', 'the', 'time', 'this', 'movie', 'was', 'made', ',', 'narrates', 'the', 'film', '.', 'His', 'anecdotes', 'and', 'witticism', ',', 'drawn', 'from', 'many', 'years', 'as', 'an', 'owner', 'and', 'driver', ',', 'lends', 'much', 'to', 'the', 'production.<br', '/><br', '/>The', 'main', 'feature', 'is', 'the', 'race', 'scenes', '.', 'Turn', 'up', 'the', 'volume', 'here', '!', 'There', 'is', 'something', 'about', 'riding', 'along', 'at', 'over', '200', 'mph', 'and', 'the', 'musical', 'score', 'that', 'totally', 'draws', 'you', 'into', 'the', 'screen', 'for', 'an', 'experience', 'you', 'will', 'not', 'forget', '.', 'Wow!<br', '/><br', '/>The', 'final', 'magical', 'element', 'is', 'the', 'humanity', 'of', 'the', 'Andretti', 'family', '.', 'This', 'god', 'of', 'the', 'racing', 'world', ',', 'Mario', 'Andretti', ',', 'is', 'loving', 'father', 'who', 'proudly', 'watches', 'over', 'his', 'son', \"'s\", 'career', '.', 'They', 'work', 'together', 'so', 'well', 'that', 'every', 'father', 'and', 'son', 'should', 'see', 'this', '.', 'You', 'can', 'tell', 'that', 'they', 'are', 'a', 'close', 'family', '.', 'I', 'wish', 'we', 'could', 'all', 'have', 'that', 'experience', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JiPxQAOCnuv"
   },
   "source": [
    "- 由于我们现在只有train/test这两个分类，所以我们需要创建一个新的validation set。我们可以使用`.split()`创建新的分类。\n",
    "- 默认的数据分割是 70、30，如果我们声明`split_ratio`，可以改变split之间的比例，`split_ratio=0.8`表示80%的数据是训练集，20%是验证集。\n",
    "- 我们还声明`random_state`这个参数，确保我们每次分割的数据集都是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xba-wyf_Cnux"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKK2W2cyCnu1"
   },
   "source": [
    "检查一下现在每个部分有多少条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1554,
     "status": "ok",
     "timestamp": 1582441253691,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "Y1yZTV4OCnu2",
    "outputId": "dad037b8-d17a-4b28-a3b2-e4facb2593bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_TmlQ2GCnu6"
   },
   "source": [
    "- 下一步我们需要创建 _vocabulary_ 。_vocabulary_ 就是把每个单词一一映射到一个数字。\n",
    "![](assets/sentiment5.png)\n",
    "- 我们使用最常见的25k个单词来构建我们的单词表，用`max_size`这个参数可以做到这一点。\n",
    "- 所有其他的单词都用`<unk>`来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 441236,
     "status": "ok",
     "timestamp": 1582441697382,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "y_k9FQy7Cnu7",
    "outputId": "bbb67b44-9d72-441f-885e-63cccae08b78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                          \n",
      "100%|█████████▉| 398449/400000 [00:15<00:00, 23640.09it/s]"
     ]
    }
   ],
   "source": [
    "# TEXT.build_vocab(train_data, max_size=25000)\n",
    "# LABEL.build_vocab(train_data)\n",
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\", unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1699,
     "status": "ok",
     "timestamp": 1582441705205,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "iKhNpuSBCnvA",
    "outputId": "46e1461c-0ee7-48f2-c01a-aff260558d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRV9FStoCnvE"
   },
   "source": [
    "- 当我们把句子传进模型的时候，我们是按照一个个 _batch_ 穿进去的，也就是说，我们一次传入了好几个句子，而且每个batch中的句子必须是相同的长度。为了确保句子的长度相同，TorchText会把短的句子pad到和最长的句子等长。\n",
    "![](assets/sentiment6.png)\n",
    "- 下面我们来看看训练数据集中最常见的单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1773,
     "status": "ok",
     "timestamp": 1582441815738,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "WS5h8XljCnvF",
    "outputId": "dad245b5-ae5e-429c-c69e-78bc04c92087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 204892), (',', 193632), ('.', 166240), ('and', 110279), ('a', 109963), ('of', 101362), ('to', 94397), ('is', 76931), ('in', 61995), ('I', 54249), ('it', 53663), ('that', 49592), ('\"', 44767), (\"'s\", 43364), ('this', 42330), ('-', 37499), ('/><br', 35975), ('was', 34954), ('as', 30632), ('with', 30266)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dCiTlh6CnvI"
   },
   "source": [
    "我们可以直接用 `stoi`(**s**tring **to** **i**nt) 或者 `itos` (**i**nt **to**  **s**tring) 来查看我们的单词表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1699,
     "status": "ok",
     "timestamp": 1582441825712,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "0VBdu5c1CnvJ",
    "outputId": "1036c19b-1f6d-4f6b-80e6-1ea5c29b8e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67mVJf65CnvQ"
   },
   "source": [
    "查看labels。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1708,
     "status": "ok",
     "timestamp": 1582441834073,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "2Jcg9-APCnvR",
    "outputId": "d377db5e-8596-43ff-a232-279ea0c4b860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f800315f2f0>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E65MZ-lCCnvW"
   },
   "source": [
    "- 最后一步数据的准备是创建iterators。每个itartion都会返回一个batch的examples。\n",
    "- 我们会使用`BucketIterator`。`BucketIterator`会把长度差不多的句子放到同一个batch中，确保每个batch中不出现太多的padding。\n",
    "- 严格来说，我们这份notebook中的模型代码都有一个问题，也就是我们把`<pad>`也当做了模型的输入进行训练。更好的做法是在模型中把由`<pad>`产生的输出给消除掉。在这节课中我们简单处理，直接把`<pad>`也用作模型输入了。由于`<pad>`数量不多，模型的效果也不差。\n",
    "- 如果我们有GPU，还可以指定每个iteration返回的tensor都在GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfzPbe2fCnvY"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUm9DgPaCnvc"
   },
   "source": [
    "## Word Averaging模型\n",
    "\n",
    "- 我们首先介绍一个简单的Word Averaging模型。这个模型非常简单，我们把每个单词都通过`Embedding`层投射成word embedding vector，然后把一句话中的所有word vector做个平均，就是整个句子的vector表示了。接下来把这个sentence vector传入一个`Linear`层，做分类即可。\n",
    "\n",
    "![](assets/sentiment8.png)\n",
    "\n",
    "- 我们使用[`avg_pool2d`](https://pytorch.org/docs/stable/nn.html?highlight=avg_pool2d#torch.nn.functional.avg_pool2d)来做average pooling。我们的目标是把sentence length那个维度平均成1，然后保留embedding这个维度。\n",
    "\n",
    "![](assets/sentiment9.png)\n",
    "\n",
    "- `avg_pool2d`的kernel size是 (`embedded.shape[1]`, 1)，所以句子长度的那个维度会被压扁。\n",
    "\n",
    "![](assets/sentiment10.png)\n",
    "\n",
    "![](assets/sentiment11.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJtCMVHCCnve"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WordAVGModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text) # [sent len, batch size, emb dim]\n",
    "        embedded = embedded.permute(1, 0, 2) # [batch size, sent len, emb dim]\n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) # [batch size, embedding_dim]\n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAqCSa94Cnvj"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = WordAVGModel(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1736,
     "status": "ok",
     "timestamp": 1582441930595,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "K8Fma6VQCnvm",
    "outputId": "78e9ccdb-7900-44ca-f0af-dcc79f30334e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,500,301 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1615,
     "status": "ok",
     "timestamp": 1582442602300,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "M7tdDAJeCnvp",
    "outputId": "22bf8a96-431d-483e-97a0-7badc29b280e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.9961,  1.2830, -0.0148,  ...,  1.4615,  1.6337, -1.4375],\n",
       "        [-0.5914, -0.4527,  0.3947,  ...,  0.8230, -0.3632,  1.0246],\n",
       "        [ 2.9104,  0.5608, -0.2070,  ...,  2.1068,  0.7176, -0.2904]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2gwkLVQCnvs"
   },
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ol4wl6VmCnvv"
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IrPZVndICnvw"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RB8Vtvp7Cnvz"
   },
   "source": [
    "计算预测的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bh9tcLcoCnv0"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCB0J_xnCnv3"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    total_len = 0\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * len(batch.label)\n",
    "        epoch_acc += acc.item() * len(batch.label)\n",
    "        total_len += len(batch.label)\n",
    "        \n",
    "    return epoch_loss / total_len, epoch_acc / total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "td_eCTZRCnv6"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    total_len = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item() * len(batch.label)\n",
    "            epoch_acc += acc.item() * len(batch.label)\n",
    "            total_len += len(batch.label)\n",
    "    return epoch_loss / total_len, epoch_acc / total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGE-G_q-Cnv-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45240,
     "status": "ok",
     "timestamp": 1582443378884,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "WEb3KbQ-CnwB",
    "outputId": "dc926c16-6929-4480-8d32-acf35d381e82",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.644 | Train Acc: 73.55%\n",
      "\t Val. Loss: 0.499 |  Val. Acc: 76.32%\n",
      "Epoch: 02 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.572 | Train Acc: 79.38%\n",
      "\t Val. Loss: 0.440 |  Val. Acc: 80.01%\n",
      "Epoch: 03 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.499 | Train Acc: 83.51%\n",
      "\t Val. Loss: 0.411 |  Val. Acc: 82.61%\n",
      "Epoch: 04 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.438 | Train Acc: 86.33%\n",
      "\t Val. Loss: 0.410 |  Val. Acc: 84.51%\n",
      "Epoch: 05 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.388 | Train Acc: 87.95%\n",
      "\t Val. Loss: 0.415 |  Val. Acc: 85.93%\n",
      "Epoch: 06 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.347 | Train Acc: 89.17%\n",
      "\t Val. Loss: 0.426 |  Val. Acc: 86.83%\n",
      "Epoch: 07 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.317 | Train Acc: 90.03%\n",
      "\t Val. Loss: 0.441 |  Val. Acc: 87.21%\n",
      "Epoch: 08 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.293 | Train Acc: 90.90%\n",
      "\t Val. Loss: 0.462 |  Val. Acc: 87.71%\n",
      "Epoch: 09 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.269 | Train Acc: 91.52%\n",
      "\t Val. Loss: 0.476 |  Val. Acc: 88.21%\n",
      "Epoch: 10 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.253 | Train Acc: 92.14%\n",
      "\t Val. Loss: 0.492 |  Val. Acc: 88.45%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'wordavg-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdDBt75aCnwE"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1713,
     "status": "ok",
     "timestamp": 1582443592070,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "aI2c1A56CnwK",
    "outputId": "13506b84-6098-48a3-c54e-9be9b163ee0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.676174646001831e-28"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1582443593803,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "G9x9AoiHCnwO",
    "outputId": "e95594eb-2f9a-4341-f64f-1aa8c078fcaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"This film is great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SY-CGsCCnwR"
   },
   "source": [
    "## RNN模型\n",
    "\n",
    "- 下面我们尝试把模型换成一个**recurrent neural network** (RNN)。RNN经常会被用来encode一个sequence\n",
    "$$h_t = \\text{RNN}(x_t, h_{t-1})$$\n",
    "- 我们使用最后一个hidden state $h_T$来表示整个句子。\n",
    "- 然后我们把$h_T$通过一个线性变换$f$，然后用来预测句子的情感。\n",
    "\n",
    "![](assets/sentiment1.png)\n",
    "\n",
    "![](assets/sentiment7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t3qyM5WaCnwT"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n",
    "                 n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text)) #[sent len, batch size, emb dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)) # [batch size, hid dim * num directions]\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-Pn7JsACnwV"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "            N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1776,
     "status": "ok",
     "timestamp": 1582444313596,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "eYmXtYhaCnwX",
    "outputId": "bf13c67c-8d27-449b-f5b7-28a4ba5cdf2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,810,857 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1681,
     "status": "ok",
     "timestamp": 1582444319513,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "a3cNO1eWCnwb",
    "outputId": "2b6a181d-3a37-4da4-b3ce-0609c8ffc9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [-0.9961,  1.2830, -0.0148,  ...,  1.4615,  1.6337, -1.4375],\n",
      "        [-0.5914, -0.4527,  0.3947,  ...,  0.8230, -0.3632,  1.0246],\n",
      "        [ 2.9104,  0.5608, -0.2070,  ...,  2.1068,  0.7176, -0.2904]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34GIBIPjCnwg"
   },
   "source": [
    "## 训练RNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmz8sprNCnwh"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 458283,
     "status": "error",
     "timestamp": 1582444784730,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "BZEnxgxSCnwj",
    "outputId": "e5400dd5-1325-4ed6-9227-5044afc30175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 2m 10s\n",
      "\tTrain Loss: 0.681 | Train Acc: 56.24%\n",
      "\t Val. Loss: 0.669 |  Val. Acc: 62.40%\n",
      "Epoch: 02 | Epoch Time: 2m 12s\n",
      "\tTrain Loss: 0.682 | Train Acc: 54.74%\n",
      "\t Val. Loss: 0.716 |  Val. Acc: 50.92%\n",
      "Epoch: 03 | Epoch Time: 2m 15s\n",
      "\tTrain Loss: 0.686 | Train Acc: 54.26%\n",
      "\t Val. Loss: 0.636 |  Val. Acc: 65.45%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-69caf2f6e603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-5588f5ae354e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'lstm-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWDE0Aj4Cnwm"
   },
   "source": [
    "You may have noticed the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which we'll improve in the next notebook.\n",
    "\n",
    "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10273,
     "status": "ok",
     "timestamp": 1582444799830,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "f9Fx57xtDzW_",
    "outputId": "eae3fbc5-cada-47d2-c1f7-035f9dd8f151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 23 07:59:55 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   71C    P0    31W /  70W |   8269MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_h_mp-TGCnwm"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('lstm-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyWYqR9nCnwp"
   },
   "source": [
    "## CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jo1qDMbbCnwp"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, \n",
    "                 filter_sizes, output_dim, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        text = text.permute(1, 0) # [batch size, sent len]\n",
    "        embedded = self.embedding(text) # [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1) # [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPqLzYYjCnws"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 107443,
     "status": "ok",
     "timestamp": 1582445661767,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "1jquyng3Cnwv",
    "outputId": "c5de0e68-a83b-4b1d-b90f-aa18f91e9365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 20s\n",
      "\tTrain Loss: 0.654 | Train Acc: 61.17%\n",
      "\t Val. Loss: 0.520 |  Val. Acc: 75.48%\n",
      "Epoch: 02 | Epoch Time: 0m 20s\n",
      "\tTrain Loss: 0.428 | Train Acc: 80.50%\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 84.84%\n",
      "Epoch: 03 | Epoch Time: 0m 20s\n",
      "\tTrain Loss: 0.303 | Train Acc: 87.53%\n",
      "\t Val. Loss: 0.317 |  Val. Acc: 86.44%\n",
      "Epoch: 04 | Epoch Time: 0m 20s\n",
      "\tTrain Loss: 0.223 | Train Acc: 91.25%\n",
      "\t Val. Loss: 0.305 |  Val. Acc: 87.28%\n",
      "Epoch: 05 | Epoch Time: 0m 20s\n",
      "\tTrain Loss: 0.159 | Train Acc: 94.07%\n",
      "\t Val. Loss: 0.323 |  Val. Acc: 87.01%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'CNN-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5282,
     "status": "ok",
     "timestamp": 1582445675659,
     "user": {
      "displayName": "陆轩韬",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDrmgBMzrqwdXVEfiiuZqvIsX9uJx1YC6AdoeJu=s64",
      "userId": "09875294307280000133"
     },
     "user_tz": -480
    },
    "id": "_OKuSuI9Cnwz",
    "outputId": "2d5b2793-f8cc-4f63-a3f9-5214a393ae8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.333 | Test Acc: 85.70%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('CNN-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "4.sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
